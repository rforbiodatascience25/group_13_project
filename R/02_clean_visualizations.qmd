---
title: "Clean data"
editor: visual
embed-resources: true
---

## Load libraries

```{r}
library("tidyverse")
library("here")
library("purrr")
```

## Load data

```{r}
nt_meta_path <- here("data/01_dat_meta_load.csv")
nt_feat_path <- here("data/01_dat_feature_load.csv")

ntm_dirty <- read_csv(nt_meta_path, show_col_types = FALSE)
ntf_dirty <- read_csv(nt_feat_path, show_col_types = FALSE)
```

## Metadata

First we remove unwanted columns from Metadata.

```{r}
ntm_dirty <- ntm_dirty |> select(-"3D_Structure_URL", 
                               -"Subunit_Structure")

ntm_dirty |> head()
```

Let's take a look at what organisms our proteins come from.

```{r}
ntm_dirty |> 
  count(Organism, name = "value") |> 
  ggplot(aes(x = "", y = value, fill = Organism)) +
    geom_col(width = 1) +
    coord_polar(theta = "y") +
    scale_fill_viridis_d(option = "turbo") +
    theme_void()
```

We can see multiple species commonly used in molecular biology research, with the most proteins coming from Homo sapiens, some Rattus species, Caenorhabditis elegans and some Aspergillus species. However, we also notice that there is a species called Homo_ERR, which should probably be converted to Homo in the cleaning process.

## Neurotransmitter features

```{r}
ntf_dirty |> head()
ntf_aa <- ntf_dirty |>  select(starts_with("aa_"))
ntf_rest <- ntf_dirty |>  select(-starts_with("aa_"))

ntf_aa |> head()
ntf_rest |> head()
```

## Merge datasets

Using bind_cols() would be enticing but is bad practice, because it blindly matches rows by their position. To avoid any potential problems arising from this, we create a .row_id key in each dataset and join them by that key.

```{r}
ntm_dirty2 <- ntm_dirty |> mutate(.row_id = row_number())
ntf_dirty2 <- ntf_dirty |> mutate(.row_id = row_number())

dirty_combined <- 
  full_join(ntm_dirty2, ntf_dirty2, by = ".row_id") |>
  select(-.row_id)
dirty_combined |> head()
```

## Clean data

### Asses "dirtiness" of data

First we asses number of missing values.

```{r}
dirty_combined |>
  is.na() |>
  colSums() |>
  head()
```

```{r}
sum(is.na(dirty_combined))
```

From this we can tell that our dataset only contains one NA value.

However, we know that some of the string values have an '\_ERR' attached. We should also check how many of those exist.

```{r}
dirty_combined |>
  select(where(is.character)) |>
  summarise(
    across(
      .cols = everything(),
      .fns = ~sum(str_ends(.x, '_ERR'), na.rm = TRUE)
    )
  )
```

So in all character columns there are 1-4 values that are marked as error values.

```{r}
dirty_combined |>
  select(where(is.numeric)) |>
  pivot_longer(everything(),
               names_to = "variable",
               values_to = "value") |>
  ggplot(aes(x = variable, y = log(value))) +
  geom_boxplot(outlier.size = 0.8) +
  theme_bw() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

To create this graph, we used pivot_longer() to be able to stratify the boxplots on every numeric variable. To make outliers of different variables comparable to one another, values have been log-normalized.

These last steps show all of the impurities that exist in our data, missing values for character data and numerical data, as well as outliers for numerical data. In the following steps we will show how to deal with them.

### Remove dirtiness of data

First we will start with cleaning string data by removing the "\_ERR" at the end of a string. We do this using the mutate()-function taught in class.

```{r}
cleaner_combined <- dirty_combined |>
  mutate(across(where(is.character),
                ~ str_remove(.x, "_ERR$" )))
```

```{r}
cleaner_combined |>
  select(where(is.character)) |>
  summarise(
    across(
      .cols = everything(),
      .fns = ~sum(str_ends(.x, '_ERR'), na.rm = TRUE)
    )
  )
```

Next, we will deal with the numeric outliers in our data. We will identify them using the IQR-method that boxplots use as well. Since they are artificial, it gives no biological insight to keep them, so we will impute them using the median-method. We prefer the media-method over the mean-method here, because the latter is much more sensitive to large outliers, which is what we have in our data.

```{r}
cleaner_combined <- cleaner_combined |>
  mutate(across(where(is.numeric), ~ {
       Q1  <- quantile(.x, 0.25, na.rm = TRUE)
       Q3  <- quantile(.x, 0.75, na.rm = TRUE)
       IQR_value <- IQR(.x, na.rm = TRUE)
       
       lower_fence <- Q1 - 1.5 * IQR_value
       upper_fence <- Q3 + 1.5 * IQR_value
       
       mean_val <- median(.x, na.rm = TRUE)
       
       ifelse(.x < lower_fence | .x > upper_fence,
              mean_val,
              .x)
  }))
```

```{r}
cleaner_combined |>
  select(where(is.numeric)) |>
  pivot_longer(everything(), names_to = "variable", values_to = "value") |>
  ggplot(aes(x = variable, y = log(value))) +
  geom_boxplot() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

As is visible, the outliers have been successfully dealt with.

Lastly, we save out cleaned data to our data-folder.

```{r}
clean_path <- here("data/02_data_clean.csv")
write_csv(cleaner_combined, clean_path)
```
