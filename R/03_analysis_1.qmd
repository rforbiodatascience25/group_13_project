---
title: "03_prediction"
format: html
---

## Introduction

This document focuses on predicting the receptor class (Glutamate, Cys-loop, or Other) based on the amino acid composition of the proteins. We will use a Random Forest classifier for this task.

## Loading libraries

```{r}
library("tidyverse")
library("here")
library("tidymodels")
```

## Data Loading

```{r}
clean_path <- here("data/02_data_clean.csv")
clean_df <- read_csv(clean_path, show_col_types = FALSE)
```

Lets take another quick look at the data:

```{r}

clean_df
```

## Data Preparation

Defining classes. Based on knowledge provided by Ãkos, we will split the receptors into 3 classes: Glutamate, Cys-loop and Other receptors (which includes 2 ionotropic receptors not part of the other 2 superfamilies).

```{r}
clean_classed_df <- clean_df |>
  mutate(
    Receptor_class = case_when(
      str_detect(Protein_Name, regex("glutamate", ignore_case = TRUE)) ~ 
        "Ionotropic glutamate receptor",

      str_detect(Protein_Name, regex("^Ionotropic receptor", ignore_case = TRUE)) ~
        "Other ionotropic receptor",

      TRUE ~ 
        "Cys-loop receptor"
    )
)


clean_classed_df |> count(Receptor_class)
clean_classed_df
```

Selecting only the relevant column for this predicition

```{r}
prediction_df <- clean_classed_df |>
  select(Protein_ID, Receptor_class, starts_with("aa_"), -aa_ratio_sum)
prediction_df
```

## PCA Analysis

Before modeling, let's visualize the data using PCA to see if the classes separate well based on amino acid composition.

```{r}
pca_rec <- recipe(~., data = prediction_df) |>
  update_role(Protein_ID, Receptor_class, new_role = "id") |>
  step_normalize(all_predictors()) |>
  step_pca(all_predictors())

pca_prep <- prep(pca_rec)
pca_juiced <- juice(pca_prep)

ggplot(pca_juiced, aes(PC1, PC2, color = Receptor_class)) +
  geom_point(alpha = 0.7) +
  labs(title = "PCA of Receptor Classes based on AA Composition",
       color = "Receptor Class") +
  theme_minimal()
```

```{r}
#ggsave(here("results/figures/pca_plot.svg"), width = 7, height = 5) #<- Note: higher quality but needs `svglite`
ggsave(here("results/figures/pca_plot.png"), width = 7, height = 5)
```

## Model Training

We split the data into training and test sets:

```{r}
set.seed(123)
split  <- initial_split(prediction_df, prop = 0.8, strata = Receptor_class)
train  <- training(split)
test   <- testing(split)
```

Define a recipe for the model:

```{r}
rec <- recipe(Receptor_class ~ ., data = train) |>
  update_role(Protein_ID, new_role = "id") |>
  step_normalize(all_predictors())
```

Define the Random Forest model and workflow:

```{r}
rf_spec <- rand_forest(trees = 1000) |>
  set_engine("randomForest") |>
  set_mode("classification")

wf_simple <- workflow() |>
  add_recipe(rec) |>
  add_model(rf_spec)
```

Fit the model:

```{r}
fit_simple <- wf_simple |> last_fit(split)
metrics <- collect_metrics(fit_simple)
```

## Model Evaluation

### Metrics

We evaluate the model using standard classification metrics:

-   **Accuracy**: The proportion of correctly classified instances.
-   **Brier**: measures the accuracy of probability predicition. lower is better
-   **ROC AUC**: The area under the Receiver Operating Characteristic curve. A value of 1 indicates a perfect model, while 0.5 indicates a random guess. It measures the model's ability to distinguish between classes.

```{r}
metrics2 <- metrics |>
  mutate(
    metric_label = case_when(
      .metric == "accuracy" ~ "Accuracy",
      .metric == "brier_class" ~ "Brier Score",
      .metric == "roc_auc" ~ "ROC AUC",
      TRUE ~ .metric
    ),
    estimate_lbl = sprintf("%.3f", .estimate),
    direction = case_when(
      .metric == "brier_class" ~ "Lower is better",
      TRUE ~ "Higher is better"
    )
  )

ggplot(metrics2,
       aes(x = metric_label, y = .estimate, fill = direction)) +
  geom_col(alpha = 0.6) +
  geom_text(aes(label = estimate_lbl), vjust = -0.5, size = 4) +
  scale_fill_manual(
    name = "Interpretation",
    values = c(
      "Higher is better" = "lightblue",
      "Lower is better"  = "darkblue"
    )
  ) +
  labs(
    title = "Model Performance Metrics",
    x = "Metric",
    y = "Estimate"
  ) +
  theme_minimal()


```

```{r}
ggsave(here("results/figures/metrics_plot.png"), width = 7, height = 5)
```

### Confusion Matrix

To see where the model makes mistakes, we can look at the confusion matrix.

```{r}
conf_mat_res <- collect_predictions(fit_simple) |>
  conf_mat(truth = Receptor_class, estimate = .pred_class)

conf_df <- as.data.frame(conf_mat_res$table)

ggplot(conf_df, aes(x = Truth, y = Prediction, fill = Freq)) +
  geom_tile(alpha = 0.8) +
  geom_text(aes(label = Freq), color = "white", size = 5) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "Confusion Matrix", x = "True Class", y = "Predicted Class") +
  theme_minimal()
```

```{r}
#ggsave(here("results/figures/confusion_matrix_plot.svg"), width = 7, height = 5) #<- Note: higher quality but needs `svglite`
ggsave(here("results/figures/confusion_matrix_plot.png"), width = 7, height = 5)
```

### Variable Importance

Which amino acids are most important for distinguishing the classes?

We use the **Mean Decrease Gini** as a measure of importance. It represents the total decrease in node inpurity (Gini impurity) that results from splitting on a given variable, averaged over all trees. A higher value indicates that the variable is more important for classification.

```{r}
final_fitted <- fit_simple$.workflow[[1]] |> extract_fit_parsnip()

importance_matrix <- final_fitted$fit$importance

importance_df <- data.frame(
  Variable = rownames(importance_matrix),
  Importance = importance_matrix[, "MeanDecreaseGini"]
) |>
  mutate(Variable = str_remove(Variable, "aa_")) |> #Remove 'aa_' prefix
  arrange(desc(Importance))

ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance)) +
  geom_col(aes(fill = Importance), alpha=0.9) +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  coord_flip() +
  labs(title = "Amino Acids by Importance",
       x = "Amino Acid",
       y = "Importance (Mean Decrease Gini)") +
  theme_minimal()
```

```{r}
#ggsave(here("results/figures/aa_importance_plot.svg"), width = 7, height = 5) #<- Note: higher quality but needs `svglite`
ggsave(here("results/figures/aa_importance_plot.png"), width = 7, height = 5)
```

Note: I love ggplot, it looks so good ahhhhh
